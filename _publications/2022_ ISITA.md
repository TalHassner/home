---
title: "Generalization Bounds for Deep Transfer Learning Using Majority Predictor Accuracy"
collection: publications
permalink: /publication/2022_ ISITA
excerpt: '[<font color="SkyBlue"><i>arXiv preprint</i></font>](https://arxiv.org/abs/2209.05709)'
date: 2022-10-17
venue: 'International Symposium on Information Theory and Its Applications (ISITA), Tsukuba, Japan'
paperurl: ''
citation: 'Cuong N.Nguyen, Lam Si Tung Ho, Vu Dinh, Tal Hassner, and Cuong V.Nguyen. <i>Generalization Bounds for Deep Transfer Learning Using Majority Predictor Accuracy.</i> Int. Symp. on Information Theory and Its Applications (ISITA), Tsukuba, Japan, 2022.'
---


### Abstract
We analyze new generalization bounds for deep learning models trained by transfer learning from a source to a target task. Our bounds utilize a quantity called the majority predictor accuracy, which can be computed efficiently from data. We show that our theory is useful in practice since it implies that the majority predictor accuracy can be used as a transferability measure, a fact that is also validated by our experiments.


[arXiv preprint](https://arxiv.org/abs/2209.05709)

[Bibtex](../projects/ISITA22/BibTeX.txt)



